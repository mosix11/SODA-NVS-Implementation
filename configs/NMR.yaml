# Configuration file for training SODA on NMR dataset for Novel View Synthesis
# The dataset contains 24 views for each object with constand camera distance and elevation
# and evenly spaced clockwize Azimuth angles 0, -15, -30, ..., -345.

# Categories in NMR dataset with associated IDs
# {
#             '02691156': 'Airplane',
#             '02828884': 'Bench',
#             '02933112': 'Cabinet',
#             '02958343': 'Car',
#             '03001627': 'Chair',
#             '03211117': 'Display',
#             '03636649': 'Lamp',
#             '03691459': 'Loudspeaker',
#             '04090263': 'Rifle',
#             '04256520': 'Sofa',
#             '04379243': 'Table',
#             '04401088': 'Telephone',
#             '04530566': 'Watercraft',
# }


# dataset: # 'NMR'
#   batch_size: 16
#   img_size: [64, 64]
#   num_views: 2 # If this is greater than 2 then 1 random view would treated as target view and `num_views-1` views will be source views (latents will be aggregated)
#   num_workers: 12 # Set based on the CPU cores
#   exclude_classes: ['02828884', '02933112', '03001627', '03211117', '03636649', '03691459', '04090263', '04379243', '04401088', '04530566'] # Used to exlude some of the classes from training for lighter training
#   seed: 11

# encoder:
#   arch: 'resnet18'
#   img_shape: [3, 64, 64]
#   z_dim: &z_dim 256 # Size of the latent vector generated by the encoder to guide the generation process of the diffusion denoiser
#   c_dim: &c_dim 288 # Size of the positional embedding produced for each ray = [o, d]. This is 2*6*c_pos_emb_freq
#   c_pos_emb_freq: &c_pos_emb_freq 24 # The number of frequency bands (L) of NeRF style postional encoding for wrold positions and directions

# denoiser: # The U-Net denoiser configuration
#   img_shape: [3, 64, 64]
#   t_dim: &t_dim 512 # The dimension of the time embedding vector.
#   z_dim: *z_dim # Must match encoder.z_dim
#   c_dim: *c_dim # Must match encoder.c_dim
#   c_pos_emb_freq: *c_pos_emb_freq # Must match encoder.c_pos_emb_freq
#   n_channels: 256 # Number of channels in the initial feature map that we transform the image into.
#   ch_mults: [1, 2, 2, 2] # The list of channel numbers at each resolution. The number of channels is `n_channels * ch_mults[i]`
#   is_attn: [False, True, True, False] # The list of booleans that indicate whether to use attention at each resolution
#   attn_channels_per_head: 8 # Number of channels each attention head.
#   dropout: 0.1 # The dropout rate used in the blocks of the unet.
#   n_blocks: 2 # The number of ResNet blocks at each resolution.
#   use_res_for_updown: False # Wether to do the upsample or downsample operations in the ResNet blocks (BigGAN-style)
#   self_attention_type: 'flash' # Can be `torch` for using pytorch's MHA or `flash` for using flash attention (flash-attn library must be installed).


# SODA:
#   T: 1000 # Number of diffusion time steps
#   beta_schedule: 'inverted' # Noise schedule type
#   z_drop_prob: 0.12 # CFG masking rate
#   #c_drop_prob: 0.1 # Condition masking rate

# trainer:
#   max_epochs: 800
#   warmup_epochs: 20
#   warmup_strategy: 'lin' # Between `lin`, `cos`, and `exp`
#   optimizer_type: 'adamw' # Between `adamw` and `adam` !! currentrly the model does not converge with adam and I don't know why!!!!!
#   enc_lr: 3.0e-4 # Learning rate of the encoder
#   enc_dec_lr_ratio: 2 # The ratio of encoder learning rate over denoiser learning rate
#   weight_decay: 0.05 # Optimizer weight decay
#   beta1: 0.9
#   beta2: 0.95
#   grad_clip_norm: 1 # Gradient norm clipping treshold
#   ema_decay: 0.9999 # Decay of Exponential Moving Average strategy for updating model parameters
#   linear_prob_freq_e: 50 # Frequency of evaluating the encoder with linear probe on classification of the categories on test set. Set to 0 if you don't need LP
#   sampling_freq_e: &sampling_freq_e 20 # Frequency of sampling from the model during training for visualization
#   ssim_eval_freq_e: *sampling_freq_e # Frequency of evaluating the SSIM score of the generated images of the diffusion model
#   fid_eval_freq_e: *sampling_freq_e # Frequency of evaluating the FID score of the generated images of the diffusion model
  
#   write_summary: True # Whether to write the summary and statistics of training on TensorBoard
#   run_on_gpu: True # Whether to run the training on GPU!!!!
#   use_amp: True # Whether to use AMP for training.




dataset: # 'NMR'
  batch_size: 32
  img_size: [32, 32]
  num_views: 2 # If this is greater than 2 then 1 random view would treated as target view and `num_views-1` views will be source views (latents will be aggregated)
  num_workers: 12 # Set based on the CPU cores
  exclude_classes: ['02828884', '02933112', '03001627', '03211117', '03636649', '03691459', '04090263', '04379243', '04401088', '04530566'] # Used to exlude some of the classes from training for lighter training
  seed: 11

encoder:
  arch: 'resnet18'
  img_shape: [3, 32, 32]
  z_dim: &z_dim 256 # Size of the latent vector generated by the encoder to guide the generation process of the diffusion denoiser
  c_dim: &c_dim 180 # Size of the positional embedding produced for each ray = [o, d]. This is 2*6*c_pos_emb_freq
  c_pos_emb_freq: &c_pos_emb_freq 15 # The number of frequency bands (L) of NeRF style postional encoding for wrold positions and directions

denoiser: # The U-Net denoiser configuration
  img_shape: [3, 32, 32]
  t_dim: &t_dim 512 # The dimension of the time embedding vector.
  z_dim: *z_dim # Must match encoder.z_dim
  c_dim: *c_dim # Must match encoder.c_dim
  c_pos_emb_freq: *c_pos_emb_freq # Must match encoder.c_pos_emb_freq
  n_channels: 256 # Number of channels in the initial feature map that we transform the image into.
  ch_mults: [1, 2, 2, 2] # The list of channel numbers at each resolution. The number of channels is `n_channels * ch_mults[i]`
  is_attn: [False, True, True, False] # The list of booleans that indicate whether to use attention at each resolution
  attn_channels_per_head: 8 # Number of channels each attention head.
  dropout: 0.1 # The dropout rate used in the blocks of the unet.
  n_blocks: 2 # The number of ResNet blocks at each resolution.
  use_res_for_updown: False # Wether to do the upsample or downsample operations in the ResNet blocks (BigGAN-style)
  self_attention_type: 'flash' # Can be `torch` for using pytorch's MHA or `flash` for using flash attention (flash-attn library must be installed).


SODA:
  T: 1000 # Number of diffusion time steps
  beta_schedule: 'inverted' # Noise schedule type
  z_drop_prob: 0.12 # CFG masking rate
  #c_drop_prob: 0.1 # Condition masking rate

trainer:
  max_epochs: 1000
  warmup_epochs: 30
  warmup_strategy: 'lin' # Between `lin`, `cos`, and `exp`
  optimizer_type: 'adamw' # Between `adamw` and `adam` !! currentrly the model does not converge with adam and I don't know why!!!!!
  enc_lr: 3.0e-4 # Learning rate of the encoder
  enc_dec_lr_ratio: 2 # The ratio of encoder learning rate over denoiser learning rate
  weight_decay: 0.05 # Optimizer weight decay
  beta1: 0.9
  beta2: 0.95
  grad_clip_norm: 1 # Gradient norm clipping treshold
  ema_decay: 0.9999 # Decay of Exponential Moving Average strategy for updating model parameters
  linear_prob_freq_e: 50 # Frequency of evaluating the encoder with linear probe on classification of the categories on test set. Set to 0 if you don't need LP
  sampling_freq_e: &sampling_freq_e 20 # Frequency of sampling from the model during training for visualization
  ssim_eval_freq_e: *sampling_freq_e # Frequency of evaluating the SSIM score of the generated images of the diffusion model
  fid_eval_freq_e: *sampling_freq_e # Frequency of evaluating the FID score of the generated images of the diffusion model
  
  write_summary: True # Whether to write the summary and statistics of training on TensorBoard
  run_on_gpu: True # Whether to run the training on GPU!!!!
  use_amp: True # Whether to use AMP for training.
